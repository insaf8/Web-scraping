{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63eac0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from selenium.common.exceptions import TimeoutException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c402819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "def get_info_by_text(soup, target_text):\n",
    "    try:\n",
    "        elements = soup.find_all(\"div\", class_='row row--dense')\n",
    "        for element in elements:\n",
    "            spec_name_element = element.find(\"div\", class_='spec-name col-sm-3 col-5')\n",
    "            if spec_name_element and target_text in spec_name_element.text:\n",
    "                info_value = element.find(\"span\", class_='mr-1 mb-1').text.strip()\n",
    "                return info_value\n",
    "    except (AttributeError, IndexError):\n",
    "        pass\n",
    "    return \"\"\n",
    "def get_info_by_text2(soup, target_text):\n",
    "    try:\n",
    "        elements = soup.find_all(\"div\", class_='row row--dense')[0]\n",
    "        spec_name_elements = elements.find_all(\"div\", class_='spec-name col-sm-3 col-5')\n",
    "\n",
    "        for spec_name_element in spec_name_elements:\n",
    "            if target_text in spec_name_element.text:\n",
    "                info_element = spec_name_element.find_next(\"div\", class_='col-sm-9 col-7')\n",
    "                info_value = info_element.text.strip() if info_element else \"\"\n",
    "                return info_value\n",
    "    except (AttributeError, IndexError):\n",
    "        pass\n",
    "    return \"\"\n",
    "\n",
    "def get_title(soup):\n",
    "    try:\n",
    "        title = soup.find(\"h1\", class_='text-h5 text-capitalize')\n",
    "        title_value = title.text\n",
    "        title_string = title_value.strip()\n",
    "    except (IndexError, AttributeError):\n",
    "        title_string = \"\"\n",
    "    return title_string\n",
    "def get_price(soup):\n",
    "    try:\n",
    "        price = soup.find(\"span\", dir='ltr')\n",
    "        price_value = price.text\n",
    "        price_string = price_value.strip()\n",
    "    except (IndexError, AttributeError):\n",
    "        price_string = \"\"\n",
    "    return price_string\n",
    "def get_city(soup):\n",
    "    try:\n",
    "        city = soup.find(\"div\",class_='mt-6').find(\"div\", class_='v-card v-card--flat v-sheet theme--light')\n",
    "        city_value = city.text\n",
    "        city_string = city_value.strip()\n",
    "    except (IndexError, AttributeError):\n",
    "        city_string = \"\"\n",
    "    return city_string\n",
    "def get_date(soup):\n",
    "    return get_info_by_text2(soup, 'Date')\n",
    "\n",
    "def get_views(soup):\n",
    "    return get_info_by_text2(soup, 'Vues')\n",
    "def get_gearbox(soup):\n",
    "    return get_info_by_text(soup, 'Boite')\n",
    "\n",
    "def get_version(soup):\n",
    "    return get_info_by_text(soup, 'Finition')\n",
    "\n",
    "def get_model(soup):\n",
    "    return get_info_by_text(soup, 'Modèle')\n",
    "\n",
    "def get_brand(soup):\n",
    "    return get_info_by_text(soup, 'Marque')\n",
    "\n",
    "def get_papiers(soup):\n",
    "    return get_info_by_text(soup, 'Papiers')\n",
    "\n",
    "def get_energy(soup):\n",
    "    return get_info_by_text(soup, 'Energie')\n",
    "\n",
    "def get_color(soup):\n",
    "    return get_info_by_text(soup, 'Couleur')\n",
    "\n",
    "def get_engine(soup):\n",
    "    return get_info_by_text(soup, 'Moteur')\n",
    "\n",
    "def get_km(soup):\n",
    "    return get_info_by_text(soup, 'Kilométrage')\n",
    "\n",
    "def get_year(soup):\n",
    "    return get_info_by_text(soup, 'Année')\n",
    "def getdata(url):\n",
    "    # Set up Chrome options\n",
    "    proxy_server = \"http://105.104.3.29:3128\"\n",
    "    \n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--window-size=1920,1200')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--disable-extensions')\n",
    "    options.add_argument('--disable-infobars')\n",
    "    options.add_argument(f'--proxy-server={proxy_server}')\n",
    "    \n",
    "    # Create a WebDriver instance with the specified options\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    \n",
    "    try:\n",
    "        # Navigate to the target URL\n",
    "        driver.get(url)\n",
    "    \n",
    "        # Your scraping logic goes here\n",
    "        html_content = driver.page_source\n",
    "    \n",
    "        # Parse the HTML content with BeautifulSoup\n",
    "        soup = BeautifulSoup(html_content, \"lxml\")\n",
    "    \n",
    "        # Print the title and parsed content\n",
    "        # print(driver.title)\n",
    "        #print(soup)\n",
    "    \n",
    "    except NoSuchElementException as e:\n",
    "        print(f\"Element not found: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465acdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time  # Import the time module for adding delays\n",
    "\n",
    "i = 390\n",
    "url = \"https://www.ouedkniss.com/automobiles/390\"\n",
    "\n",
    "# Open the CSV file in append mode\n",
    "with open(\"car_data_final.csv\", mode='a', newline='', encoding='utf-8') as file:\n",
    "    # Create a CSV writer object\n",
    "    csv_writer = csv.writer(file)\n",
    "\n",
    "    while i <= 500:\n",
    "        try:\n",
    "            print(i)\n",
    "            HEADERS = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',\n",
    "                       'Accept-Language': 'en-US, en;q=0.5'}\n",
    "\n",
    "            soup = getdata(url)\n",
    "\n",
    "            # Fetch links as List of Tag Objects\n",
    "            links = soup.find_all(\"a\", class_='d-flex flex-column flex-grow-1 v-card v-card--link v-sheet o-announ-card-content pb-1 theme--light')\n",
    "\n",
    "            # Loop for extracting product details from each link\n",
    "            for link in links:\n",
    "                try:\n",
    "                    new_soup = getdata(\"https://www.ouedkniss.com\" + link.get('href'))\n",
    "\n",
    "                    # Function calls to display all necessary product information\n",
    "                    row = [\n",
    "                        get_title(new_soup),\n",
    "                        get_price(new_soup),\n",
    "                        get_date(new_soup),\n",
    "                        get_views(new_soup),\n",
    "                        get_color(new_soup),\n",
    "                        get_gearbox(new_soup),\n",
    "                        get_energy(new_soup),\n",
    "                        get_engine(new_soup),\n",
    "                        get_brand(new_soup),\n",
    "                        get_model(new_soup),\n",
    "                        get_version(new_soup),\n",
    "                        get_year(new_soup),\n",
    "                        get_km(new_soup),\n",
    "                        get_city(new_soup)\n",
    "                    ]\n",
    "\n",
    "                    # Write the row to the CSV file\n",
    "                    csv_writer.writerow(row)\n",
    "\n",
    "                except Exception as inner_exception:\n",
    "                    print(f\"Inner Error: {inner_exception}. Skipping this entry.\")\n",
    "\n",
    "            url = \"https://www.ouedkniss.com/automobiles/\" + str(i + 1)\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "        except Exception as outer_exception:\n",
    "            # Print the error and the last successful value of i\n",
    "            print(f\"Outer Error: {outer_exception}. Last successful i: {i - 1}\")\n",
    "\n",
    "            # Introduce a delay before retrying (you can adjust the duration)\n",
    "            time.sleep(5)  # 5 seconds delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7405b4b-29a7-41af-b1ac-3671391301fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
